"""
Utility functions for the ZtbAi API server.
"""
from pathlib import Path
from typing import Optional

import os
from typing import Dict, Any

def find_bid_file_in_project(project_dir: Path) -> Optional[Path]:
    """åœ¨é¡¹ç›®ç›®å½•ä¸­æŸ¥æ‰¾æ‹›æ ‡æ–‡ä»¶"""
    # æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
    supported_extensions = ['.pdf', '.docx', '.doc', '.txt']

    # æ‹›æ ‡æ–‡ä»¶å…³é”®è¯
    bid_keywords = ['æ‹›æ ‡', 'æŠ•æ ‡', 'é‡‡è´­', 'å…¬å‘Š', 'tender', 'bid']

    for file_path in project_dir.rglob('*'):
        if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«æ‹›æ ‡ç›¸å…³å…³é”®è¯
            filename_lower = file_path.name.lower()
            if any(keyword in filename_lower for keyword in bid_keywords):
                return file_path

    # å¦‚æœæ²¡æ‰¾åˆ°å…³é”®è¯åŒ¹é…çš„æ–‡ä»¶ï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ”¯æŒçš„æ–‡ä»¶
    for file_path in project_dir.rglob('*'):
        if file_path.is_file() and file_path.suffix.lower() in supported_extensions:
            return file_path

    return None


from datetime import datetime
from app.core.response import create_response, create_error_response

async def save_analysis_results(project_id: str, combined_result):
    """ä¿å­˜åˆ†æç»“æœåˆ°é¡¹ç›®ç›®å½•ï¼ˆä¸¥æ ¼ä½¿ç”¨Agentäº§ç‰©ï¼Œä¸åšæ¨¡æ¿è¦†å†™ï¼‰"""
    try:
        print(f"ğŸ”„ [API] å¼€å§‹ä¿å­˜åˆ†æç»“æœï¼Œé¡¹ç›®ID: {project_id}")

        # ç»Ÿä¸€é€šè¿‡é¡¹ç›®IDè§£æè·¯å¾„ï¼Œé¿å…ç¯å¢ƒé”™ä½
        
        project_path = get_project_path_by_id(project_id)
        if not project_path:
            print(f"âŒ [API] æœªæ‰¾åˆ°é¡¹ç›®è·¯å¾„ï¼Œé¡¹ç›®ID: {project_id}")
            return create_error_response(f"æœªæ‰¾åˆ°é¡¹ç›®ID {project_id} çš„è·¯å¾„ï¼Œæ— æ³•ä¿å­˜åˆ†ææ–‡ä»¶")

        project_dir = Path(project_path)
        if not project_dir.exists():
            print(f"âŒ [API] é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_path}")
            return create_error_response(f"é¡¹ç›®ç›®å½•ä¸å­˜åœ¨: {project_path}")

        # ä»combined_resultä¸­è¯»å–Agentç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        analysis_path = combined_result.get('analysis_path') or combined_result.get('report_path')
        strategy_path = combined_result.get('strategy_path')

        # æ ¡éªŒAgentäº§ç‰©æ˜¯å¦å­˜åœ¨
        missing = []
        if not analysis_path or not Path(analysis_path).exists():
            missing.append('æ‹›æ ‡æ–‡ä»¶åˆ†ææŠ¥å‘Š.md')
        if not strategy_path or not Path(strategy_path).exists():
            missing.append('æŠ•æ ‡æ–‡ä»¶åˆ¶ä½œç­–ç•¥.md')

        if missing:
            msg = f"Agentæœªç”Ÿæˆæ–‡ä»¶æˆ–æ–‡ä»¶ä¸å­˜åœ¨: {', '.join(missing)}"
            print(f"âŒ [API] {msg}")
            return create_error_response(msg)

        # ä¸å†è¿›è¡Œä»»ä½•æ¨¡æ¿ç”Ÿæˆæˆ–è¦†å†™ï¼Œç›´æ¥ç¡®è®¤Agentäº§ç‰©
        generation_results = {
            'report': {'success': True, 'path': str(analysis_path)},
            'strategy': {'success': True, 'path': str(strategy_path)}
        }

        # æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶ä»…ç™»è®°ç°æœ‰æ–‡ä»¶
        try:
            print(f"ğŸ”„ [API] å¼€å§‹æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶...")
            await update_project_config_file(project_dir, generation_results, combined_result)
            print(f"âœ… [API] é¡¹ç›®é…ç½®æ–‡ä»¶å·²æ›´æ–°")
        except Exception as e:
            print(f"âš ï¸ [API] æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶å¤±è´¥: {e}")

        print(f"âœ… [API] åˆ†æç»“æœå·²ä¿å­˜åˆ°é¡¹ç›®ç›®å½•: {project_path}")
        return create_response(True, "ä¿å­˜åˆ†æç»“æœæˆåŠŸ", {
            'files_generated': {
                'report': generation_results.get('report', {}),
                'strategy': generation_results.get('strategy', {}),
                'config_updated': True
            },
            'project_path': project_path,
            'generation_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        })

    except Exception as e:
        print(f"âŒ [API] ä¿å­˜åˆ†æç»“æœå¤±è´¥: {e}")
        return None

import json

async def update_project_config_file(project_dir: Path, generation_results: dict, combined_result: dict):
    """æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶ï¼ˆZtbAiConfig.Ztbaiï¼‰"""
    try:
        # ä»combined_resultä¸­æå–analysis_result
        analysis_result = combined_result.get("analysis_result", {})

        config_file = project_dir / "ZtbAiConfig.Ztbai"

        # è¯»å–ç°æœ‰é…ç½®
        config_data = {}
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_content = f.read().strip()
                    if config_content:
                        config_data = json.loads(config_content)
            except (json.JSONDecodeError, Exception) as e:
                print(f"âš ï¸ [API] è¯»å–ç°æœ‰é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°é…ç½®: {e}")
                config_data = {}

        # ç¡®ä¿åŸºæœ¬ç»“æ„å­˜åœ¨
        if 'analysis_files' not in config_data:
            config_data['analysis_files'] = []
        if 'project_info' not in config_data:
            config_data['project_info'] = {}
        if 'last_updated' not in config_data:
            config_data['last_updated'] = None

        # æ·»åŠ æ–°çš„åˆ†ææ–‡ä»¶è®°å½•
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # ç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯
        new_files = []

        print(f"ğŸ” [API] æ£€æŸ¥generation_results: {generation_results}")

        if generation_results.get('report', {}).get('success'):
            report_path = generation_results['report']['path']
            print(f"ğŸ“„ [API] æ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶: {report_path}")
            new_files.append({
                'file_name': 'æ‹›æ ‡æ–‡ä»¶åˆ†ææŠ¥å‘Š.md',
                'file_path': report_path,
                'file_type': 'analysis_report',
                'generated_time': current_time,
                'file_size': Path(report_path).stat().st_size if Path(report_path).exists() else 0,
                'description': 'åŸºäºAIåˆ†æç”Ÿæˆçš„æ‹›æ ‡æ–‡ä»¶åˆ†ææŠ¥å‘Š'
            })
        else:
            print(f"âš ï¸ [API] æŠ¥å‘Šæ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {generation_results.get('report', {})}")

        if generation_results.get('strategy', {}).get('success'):
            strategy_path = generation_results['strategy']['path']
            print(f"ğŸ“„ [API] æ‰¾åˆ°ç­–ç•¥æ–‡ä»¶: {strategy_path}")
            new_files.append({
                'file_name': 'æŠ•æ ‡æ–‡ä»¶åˆ¶ä½œç­–ç•¥.md',
                'file_path': strategy_path,
                'file_type': 'strategy_document',
                'generated_time': current_time,
                'file_size': Path(strategy_path).stat().st_size if Path(strategy_path).exists() else 0,
                'description': 'åŸºäºåˆ†æç»“æœç”Ÿæˆçš„æŠ•æ ‡æ–‡ä»¶åˆ¶ä½œç­–ç•¥'
            })
        else:
            print(f"âš ï¸ [API] ç­–ç•¥æ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {generation_results.get('strategy', {})}")

        print(f"ğŸ“‹ [API] å‡†å¤‡æ·»åŠ  {len(new_files)} ä¸ªæ–‡ä»¶è®°å½•")

        # æ·»åŠ åˆ°é…ç½®ä¸­ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
        existing_files = {f.get('file_name', '') for f in config_data['analysis_files']}
        for new_file in new_files:
            if new_file['file_name'] not in existing_files:
                config_data['analysis_files'].append(new_file)
                print(f"ğŸ“„ [API] æ·»åŠ æ–°æ–‡ä»¶è®°å½•: {new_file['file_name']}")
            else:
                # æ›´æ–°ç°æœ‰è®°å½•
                for i, existing_file in enumerate(config_data['analysis_files']):
                    if existing_file.get('file_name') == new_file['file_name']:
                        config_data['analysis_files'][i] = new_file
                        print(f"ğŸ”„ [API] æ›´æ–°æ–‡ä»¶è®°å½•: {new_file['file_name']}")
                        break

        # æ›´æ–°é¡¹ç›®ä¿¡æ¯
        if analysis_result and 'basic_info' in analysis_result:
            basic_info = analysis_result['basic_info']
            config_data['project_info'].update({
                'project_name': basic_info.get('project_name', ''),
                'tender_unit': basic_info.get('tender_unit', ''),
                'project_number': basic_info.get('project_number', ''),
                'last_analysis_time': current_time,
                'analysis_type': 'comprehensive'
            })

        # æ›´æ–°æ—¶é—´æˆ³
        config_data['last_updated'] = current_time

        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… [API] é¡¹ç›®é…ç½®æ–‡ä»¶å·²æ›´æ–°: {config_file}")
        print(f"ğŸ“„ [API] æ–°å¢æ–‡ä»¶è®°å½•: {len(new_files)} ä¸ª")

    except Exception as e:
        print(f"âŒ [API] æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        raise


def get_project_path_by_id(project_id: str) -> Optional[str]:
    """æ ¹æ®é¡¹ç›®IDè·å–é¡¹ç›®è·¯å¾„"""
    try:
        print(f"ğŸ” [PATH_RESOLVER] æ ¹æ®é¡¹ç›®IDè·å–è·¯å¾„: {project_id}")

        # è¿æ¥æ•°æ®åº“è·å–é¡¹ç›®ä¿¡æ¯
        import sqlite3
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "ztbai.db")
        print(f"ğŸ” [PATH_RESOLVER] æ•°æ®åº“è·¯å¾„: {db_path}")

        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # æŸ¥è¯¢é¡¹ç›®ä¿¡æ¯
        cursor.execute("SELECT * FROM projects WHERE id = ?", (project_id,))
        project = cursor.fetchone()

        if project:
            project_path = project['project_path']
            print(f"âœ… [PATH_RESOLVER] ä»æ•°æ®åº“è·å–åˆ°é¡¹ç›®è·¯å¾„: {project_path}")
            conn.close()
            return project_path
        else:
            print(f"âŒ [PATH_RESOLVER] æ•°æ®åº“ä¸­æœªæ‰¾åˆ°é¡¹ç›®ID: {project_id}")
            # å°è¯•ä»ZtbBidProç›®å½•æŸ¥æ‰¾åŒ¹é…çš„é¡¹ç›®
            fallback_path = None  # find_project_by_id_fallback(project_id)
            if fallback_path:
                print(f"âœ… [PATH_RESOLVER] ä»ç›®å½•æŸ¥æ‰¾åˆ°é¡¹ç›®è·¯å¾„: {fallback_path}")
                conn.close()
                return fallback_path
            conn.close()
            return None

    except Exception as e:
        print(f"âŒ [PATH_RESOLVER] è·å–é¡¹ç›®è·¯å¾„å¤±è´¥: {e}")
        import traceback
        print(f"âŒ [PATH_RESOLVER] é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        return None

def upsert_task_record(project_id: str, step_key: str, task_id: str, status: str, progress: int = 0, payload: Optional[Dict[str, Any]] = None, error: Optional[str] = None):
    try:
        import sqlite3, json
        now = datetime.now().isoformat()
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "ztbai.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        # è¯»å–å·²æœ‰
        cursor.execute("SELECT id, started_at FROM tasks WHERE project_id=? AND step_key=? AND task_id=? ORDER BY id DESC LIMIT 1", (project_id, step_key, task_id))
        row = cursor.fetchone()
        started_at = row[1] if row else (now if status == "in_progress" else None)
        completed_at = now if status == "completed" else None
        cancelled_at = now if status == "cancelled" else None
        payload_txt = json.dumps(payload, ensure_ascii=False) if payload else None
        idk = None
        try:
            idk = payload.get("idempotency_key") if payload else None
        except Exception:
            idk = None
        # æ’å…¥ä¸€æ¡å¿«ç…§è®°å½•ï¼ˆä¿ç•™å†å²ï¼‰
        cursor.execute(
            """
            INSERT INTO tasks (task_id, project_id, step_key, status, progress, payload, error, started_at, updated_at, completed_at, cancelled_at, idempotency_key)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            (task_id, project_id, step_key, status, int(progress or 0), payload_txt, error, started_at, now, completed_at, cancelled_at, idk)
        )
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"âš ï¸ å†™å…¥ä»»åŠ¡è®°å½•å¤±è´¥: {e}")

def api_log_step_event(step_key: str, project_id: str, event: str,
                        task_id: Optional[str] = None,
                        idempotency_key: Optional[str] = None,
                        status: Optional[str] = None,
                        progress: Optional[int] = None,
                        extra: Optional[Dict[str, Any]] = None) -> None:
    try:
        from core.logging_config import get_api_logger
        api_logger = get_api_logger()
        fields = {
            "event_type": "step_event",
            "step_key": step_key,
            "project_id": project_id,
            "event": event,
        }
        if task_id is not None:
            fields["task_id"] = task_id
        if idempotency_key is not None:
            fields["idempotency_key"] = idempotency_key
        if status is not None:
            fields["status"] = status
        if progress is not None:
            fields["progress"] = progress
        if extra:
            fields.update(extra)
        api_logger.logger.info(f"step_event {step_key} {event}", extra={"extra_fields": fields})
    except Exception:
        pass

async def update_project_progress_internal(project_id: str, step_key: str, step_name: str, status: str, progress: int):
    pass


import json





import json





async def update_project_config_file(project_dir: Path, generation_results: dict, combined_result: dict):
    """æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶ï¼ˆZtbAiConfig.Ztbaiï¼‰"""
    try:
        # ä»combined_resultä¸­æå–analysis_result
        analysis_result = combined_result.get("analysis_result", {})

        config_file = project_dir / "ZtbAiConfig.Ztbai"

        # è¯»å–ç°æœ‰é…ç½®
        config_data = {}
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    config_content = f.read().strip()
                    if config_content:
                        config_data = json.loads(config_content)
            except (json.JSONDecodeError, Exception) as e:
                print(f"âš ï¸ [API] è¯»å–ç°æœ‰é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œå°†åˆ›å»ºæ–°é…ç½®: {e}")
                config_data = {}

        # ç¡®ä¿åŸºæœ¬ç»“æ„å­˜åœ¨
        if 'analysis_files' not in config_data:
            config_data['analysis_files'] = []
        if 'project_info' not in config_data:
            config_data['project_info'] = {}
        if 'last_updated' not in config_data:
            config_data['last_updated'] = None

        # æ·»åŠ æ–°çš„åˆ†ææ–‡ä»¶è®°å½•
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # ç”Ÿæˆçš„æ–‡ä»¶ä¿¡æ¯
        new_files = []

        print(f"ğŸ” [API] æ£€æŸ¥generation_results: {generation_results}")

        if generation_results.get('report', {}).get('success'):
            report_path = generation_results['report']['path']
            print(f"ğŸ“„ [API] æ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶: {report_path}")
            new_files.append({
                'file_name': 'æ‹›æ ‡æ–‡ä»¶åˆ†ææŠ¥å‘Š.md',
                'file_path': report_path,
                'file_type': 'analysis_report',
                'generated_time': current_time,
                'file_size': Path(report_path).stat().st_size if Path(report_path).exists() else 0,
                'description': 'åŸºäºAIåˆ†æç”Ÿæˆçš„æ‹›æ ‡æ–‡ä»¶åˆ†ææŠ¥å‘Š'
            })
        else:
            print(f"âš ï¸ [API] æŠ¥å‘Šæ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {generation_results.get('report', {})}")

        if generation_results.get('strategy', {}).get('success'):
            strategy_path = generation_results['strategy']['path']
            print(f"ğŸ“„ [API] æ‰¾åˆ°ç­–ç•¥æ–‡ä»¶: {strategy_path}")
            new_files.append({
                'file_name': 'æŠ•æ ‡æ–‡ä»¶åˆ¶ä½œç­–ç•¥.md',
                'file_path': strategy_path,
                'file_type': 'strategy_document',
                'generated_time': current_time,
                'file_size': Path(strategy_path).stat().st_size if Path(strategy_path).exists() else 0,
                'description': 'åŸºäºåˆ†æç»“æœç”Ÿæˆçš„æŠ•æ ‡æ–‡ä»¶åˆ¶ä½œç­–ç•¥'
            })
        else:
            print(f"âš ï¸ [API] ç­–ç•¥æ–‡ä»¶ç”Ÿæˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {generation_results.get('strategy', {})}")

        print(f"ğŸ“‹ [API] å‡†å¤‡æ·»åŠ  {len(new_files)} ä¸ªæ–‡ä»¶è®°å½•")

        # æ·»åŠ åˆ°é…ç½®ä¸­ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
        existing_files = {f.get('file_name', '') for f in config_data['analysis_files']}
        for new_file in new_files:
            if new_file['file_name'] not in existing_files:
                config_data['analysis_files'].append(new_file)
                print(f"ğŸ“„ [API] æ·»åŠ æ–°æ–‡ä»¶è®°å½•: {new_file['file_name']}")
            else:
                # æ›´æ–°ç°æœ‰è®°å½•
                for i, existing_file in enumerate(config_data['analysis_files']):
                    if existing_file.get('file_name') == new_file['file_name']:
                        config_data['analysis_files'][i] = new_file
                        print(f"ğŸ”„ [API] æ›´æ–°æ–‡ä»¶è®°å½•: {new_file['file_name']}")
                        break

        # æ›´æ–°é¡¹ç›®ä¿¡æ¯
        if analysis_result and 'basic_info' in analysis_result:
            basic_info = analysis_result['basic_info']
            config_data['project_info'].update({
                'project_name': basic_info.get('project_name', ''),
                'tender_unit': basic_info.get('tender_unit', ''),
                'project_number': basic_info.get('project_number', ''),
                'last_analysis_time': current_time,
                'analysis_type': 'comprehensive'
            })

        # æ›´æ–°æ—¶é—´æˆ³
        config_data['last_updated'] = current_time

        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… [API] é¡¹ç›®é…ç½®æ–‡ä»¶å·²æ›´æ–°: {config_file}")
        print(f"ğŸ“„ [API] æ–°å¢æ–‡ä»¶è®°å½•: {len(new_files)} ä¸ª")

    except Exception as e:
        print(f"âŒ [API] æ›´æ–°é¡¹ç›®é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def insert_step_result_record(project_id: str, step_key: str, data_obj: Dict[str, Any]):
    try:
        import sqlite3, json
        now = datetime.now().isoformat()
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "ztbai.db")
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute(
            """
            INSERT INTO step_results (project_id, step_key, result_json, created_at)
            VALUES (?, ?, ?, ?)
            """,
            (project_id, step_key, json.dumps(data_obj, ensure_ascii=False), now)
        )
        conn.commit()
        conn.close()
    except Exception as e:
        print(f"âš ï¸ å†™å…¥æ­¥éª¤ç»“æœå¤±è´¥: {e}")

        raise





"""
åŠ å¯†å·¥å…·ç±»
æä¾›AES-256-GCMåŠ å¯†åŠŸèƒ½
"""

import base64
import hashlib
from cryptography.hazmat.primitives.ciphers.aead import AESGCM
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import os


class AESEncryption:
    """AES-256-GCMåŠ å¯†å·¥å…·ç±»"""

    def __init__(self, password: str = "My060322@"):
        """
        åˆå§‹åŒ–åŠ å¯†å™¨

        Args:
            password: åŠ å¯†å¯†ç 
        """
        self.password = password.encode('utf-8')

    def _derive_key(self, salt: bytes) -> bytes:
        """
        ä»å¯†ç æ´¾ç”Ÿå¯†é’¥

        Args:
            salt: ç›å€¼

        Returns:
            æ´¾ç”Ÿçš„å¯†é’¥
        """
        kdf = PBKDF2HMAC(
            algorithm=hashes.SHA256(),
            length=32,  # AES-256éœ€è¦32å­—èŠ‚å¯†é’¥
            salt=salt,
            iterations=100000,
        )
        return kdf.derive(self.password)

    def encrypt(self, plaintext: str) -> str:
        """
        åŠ å¯†æ–‡æœ¬

        Args:
            plaintext: æ˜æ–‡

        Returns:
            åŠ å¯†åçš„base64ç¼–ç å­—ç¬¦ä¸²
        """
        try:
            # ç”Ÿæˆéšæœºç›å€¼å’Œnonce
            salt = os.urandom(16)
            nonce = os.urandom(12)  # GCMæ¨¡å¼æ¨è12å­—èŠ‚nonce

            # æ´¾ç”Ÿå¯†é’¥
            key = self._derive_key(salt)

            # åˆ›å»ºAESGCMå®ä¾‹
            aesgcm = AESGCM(key)

            # åŠ å¯†
            ciphertext = aesgcm.encrypt(nonce, plaintext.encode('utf-8'), None)

            # ç»„åˆï¼šsalt + nonce + ciphertext
            encrypted_data = salt + nonce + ciphertext

            # è¿”å›base64ç¼–ç 
            return base64.b64encode(encrypted_data).decode('utf-8')

        except Exception as e:
            raise Exception(f"åŠ å¯†å¤±è´¥: {str(e)}")

    def decrypt(self, encrypted_text: str) -> str:
        """
        è§£å¯†æ–‡æœ¬

        Args:
            encrypted_text: åŠ å¯†çš„base64ç¼–ç å­—ç¬¦ä¸²

        Returns:
            è§£å¯†åçš„æ˜æ–‡
        """
        try:
            # base64è§£ç 
            encrypted_data = base64.b64decode(encrypted_text.encode('utf-8'))

            # åˆ†ç¦»ç»„ä»¶
            salt = encrypted_data[:16]
            nonce = encrypted_data[16:28]
            ciphertext = encrypted_data[28:]

            # æ´¾ç”Ÿå¯†é’¥
            key = self._derive_key(salt)

            # åˆ›å»ºAESGCMå®ä¾‹
            aesgcm = AESGCM(key)

            # è§£å¯†
            plaintext = aesgcm.decrypt(nonce, ciphertext, None)

            return plaintext.decode('utf-8')

        except Exception as e:
            raise Exception(f"è§£å¯†å¤±è´¥: {str(e)}")


def calculate_file_md5(file_path: str) -> str:
    """
    è®¡ç®—æ–‡ä»¶MD5å€¼

    Args:
        file_path: æ–‡ä»¶è·¯å¾„

    Returns:
        MD5å“ˆå¸Œå€¼
    """
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()


def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œæ›¿æ¢ç‰¹æ®Šå­—ç¬¦
    æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„å‘½åè§„èŒƒï¼š
    åŸæ–‡ä»¶ï¼šä¸­æ‹›æ¶¦ä¿¡é¡¹ç›®@AAA.pdf
    è§„èŒƒåï¼šä¸­æ‹›æ¶¦ä¿¡é¡¹ç›®_AAA_20250720_122622

    Args:
        filename: åŸå§‹æ–‡ä»¶å

    Returns:
        æ¸…ç†åçš„æ–‡ä»¶å
    """
    import re
    from datetime import datetime

    # ç§»é™¤æ–‡ä»¶æ‰©å±•å
    name_without_ext = filename.rsplit('.', 1)[0] if '.' in filename else filename

    # æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿ï¼ˆåŒ…æ‹¬@ã€ç©ºæ ¼ã€ç‰¹æ®Šç¬¦å·ç­‰ï¼‰
    # ä¿ç•™ä¸­æ–‡å­—ç¬¦ã€è‹±æ–‡å­—æ¯ã€æ•°å­—ï¼Œå…¶ä»–å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    sanitized = re.sub(r'[\w\u4e00-\u9fff]', '_', name_without_ext)

    # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
    sanitized = re.sub(r'_+', '_', sanitized)

    # ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„ä¸‹åˆ’çº¿
    sanitized = sanitized.strip('_')

    # å¦‚æœä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not sanitized:
        sanitized = "project"

    # æ·»åŠ æ—¶é—´æˆ³ YYYYMMDD_HHMMSS
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    final_name = f"{sanitized}_{timestamp}"

    return final_name
